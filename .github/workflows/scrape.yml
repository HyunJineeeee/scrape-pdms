name: Scrape PDMS

on:
  workflow_dispatch:
  schedule:
    - cron: "0 21 * * 1"   # ë§¤ì£¼ í™” 06:00 KST (ì›” 21:00 UTC)

jobs:
  run:
    runs-on: ubuntu-latest

    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"
          cache: "pip"                # ğŸ”¥ pip ìºì‹œ í™œì„±í™”

      - name: Cache Playwright browsers
        uses: actions/cache@v4
        with:
          path: ~/.cache/ms-playwright  # ğŸ”¥ ë¸Œë¼ìš°ì € ìºì‹œ (ì„¤ì¹˜ì‹œê°„ ëŒ€í­ ë‹¨ì¶•)
          key: ${{ runner.os }}-ms-playwright-${{ hashFiles('requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-ms-playwright-

      - name: Install deps (fast)
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          python -m playwright install --with-deps chromium

      - name: Run scraper
        run: |
          python scrape_pdms.py

      - name: Upload CSV artifact
        if: success()
        uses: actions/upload-artifact@v4
        with:
          name: pdms-learning-companies
          path: pdms_learning_companies.csv

      - name: Upload debug artifacts if failed
        if: failure()
        uses: actions/upload-artifact@v4
        with:
          name: debug
          path: |
            *.png
            *.log
